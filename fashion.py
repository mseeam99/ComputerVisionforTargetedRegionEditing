# -*- coding: utf-8 -*-
"""fashion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjowwaDWYiw_xma3471aLshFQbJA2p8O
"""

!python3.11 -m pip install --upgrade pip
!pip install ninja
!pip install diffusers transformers accelerate scipy opencv-python

import torch
import PIL, cv2
from PIL import Image
from io import BytesIO
from IPython.display import display
import base64, json, requests
from matplotlib import pyplot as plt
import numpy as np
import copy

!pip install torchvision
import torch

!pip install torch
!pip install torchvision

import torchvision.transforms as transforms

# Commented out IPython magic to ensure Python compatibility.
!pip install -q git+https://github.com/openai/CLIP.git
!git clone https://github.com/timojl/clipseg
# %cd clipseg
!wget https://owncloud.gwdg.de/index.php/s/ioHbRzFx6th32hn/download -O weights.zip
!unzip -d weights -j weights.zip

import clip
from models.clipseg import CLIPDensePredT

model = CLIPDensePredT(version='ViT-B/16', reduce_dim=64)
model.eval()

model.load_state_dict(torch.load('weights/rd64-uni.pth', map_location=torch.device('cpu')), strict=False)

### imp Stable Diffusion model
from diffusers import StableDiffusionInpaintPipeline, EulerDiscreteScheduler

model_dir = "stabilityai/stable-diffusion-2-inpainting"

scheduler = EulerDiscreteScheduler.from_pretrained(model_dir, subfolder="scheduler")

pipe = StableDiffusionInpaintPipeline.from_pretrained(model_dir,
                                                      scheduler=scheduler,
                                                      revision="fp16",
                                                      torch_dtype=torch.float16)
pipe = pipe.to("cuda")
pipe.enable_xformers_memory_efficient_attention()

from google.colab import files
from PIL import Image
import io
import torch
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import copy
from torchvision.transforms.functional import to_pil_image

uploaded = files.upload()

filename = next(iter(uploaded))

source_image = Image.open(io.BytesIO(uploaded[filename]))

target_width, target_height = 512, 512
width, height = source_image.size
print(f"Source image size: {source_image.size}")

source_image = source_image.resize((target_width, target_height), Image.LANCZOS)
print(f"Target image size: {source_image.size}")

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

tensor_image = transform(source_image).unsqueeze(0)

plt.imshow(source_image)
plt.axis('off')
plt.show()


# Create masks for the parts of the clothes to be identified

#################### DO PROMPT ENGINEERING WHAT YOU WANT TO CHANGE STARTS #####################
prompts = ['a hat', 'a dark skirt', 'shoes', 'a white shirt']
#################### DO PROMPT ENGINEERING WHAT YOU WANT TO CHANGE ENDS #######################

with torch.no_grad():
    preds = model(tensor_image.repeat(len(prompts), 1, 1, 1), prompts)[0]

def create_image_grid(original_image, images, names, rows, columns):
    names = copy.copy(names)
    images = copy.copy(images)

    if torch.is_tensor(images):
        assert images.size(0) == len(names), "Number of images and names should be equal"

        images = [to_pil_image(torch.sigmoid(img)) for img in images]
    else:
        assert len(images) == len(names), "Number of images and names should be equal"

    total_images = len(images) + 1
    if total_images < rows * columns:
        rows = (total_images + columns - 1) // columns
        columns = (total_images + rows - 1) // rows

    images.insert(0, original_image)

    names.insert(0, '')

    fig, axes = plt.subplots(rows, columns, figsize=(15, 15))

    for idx, (img, name) in enumerate(zip(images, names)):
        row, col = divmod(idx, columns)

        axes[row, col].imshow(img, cmap='gray' if idx > 0 and torch.is_tensor(images) else None)

        axes[row, col].set_title(name)

        axes[row, col].axis('off')

    for idx in range(len(images), rows * columns):
        row, col = divmod(idx, columns)
        axes[row, col].axis('off')

    plt.tight_layout()

    plt.show()


create_image_grid(source_image, preds, prompts, 2, 3)

mask_number = 1

processed_mask = torch.special.ndtr(preds[mask_number][0])

stable_diffusion_mask = transforms.ToPILImage()(processed_mask)
plt.imshow(stable_diffusion_mask)
plt.axis('off')
plt.show()

num_images_per_prompt = 4
inpainting_prompts = ["a skirt full of text",  "blue flowers", "white flowers", "a zebra skirt"]

generator = torch.Generator(device="cuda").manual_seed(77)  # 155, 77

encoded_images = []
for i in range(num_images_per_prompt):
    image = pipe(prompt=inpainting_prompts[i], guidance_scale=7.5, num_inference_steps=60, generator=generator, image=source_image, mask_image=stable_diffusion_mask).images[0]
    encoded_images.append(image)

create_image_grid(source_image, encoded_images, inpainting_prompts, 2, 3)

def create_image_plus_masks_grid(original_image, images, names, rows, columns):
    names = copy.copy(names)
    images = copy.copy(images)
    if torch.is_tensor(images):
        assert images.size(0) == len(names), "Number of images and names should be equal"
        images = [to_pil_image(torch.sigmoid(img)) for img in images]
    else:
        assert len(images) == len(names), "Number of images and names should be equal"

    total_images = len(images) + 1
    if total_images < rows * columns:
        rows = (total_images + columns - 1) // columns
        columns = (total_images + rows - 1) // rows

    images.insert(0, original_image)

    names.insert(0, '')

    fig, axes = plt.subplots(rows, columns, figsize=(15, 15))

    for idx, (img, name) in enumerate(zip(images, names)):
        row, col = divmod(idx, columns)

        axes[row, col].imshow(img, cmap='gray' if idx > 0 and torch.is_tensor(images) else None)

        axes[row, col].set_title(name)

        axes[row, col].axis('off')

    for idx in range(len(images), rows * columns):
        row, col = divmod(idx, columns)

        axes[row, col].axis('off')

    plt.tight_layout()

    plt.show()


create_image_plus_masks_grid(source_image, preds, prompts, 2, 3)

